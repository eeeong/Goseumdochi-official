{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20171510-38a4-48c6-983d-221f939f753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSY\\anaconda3\\envs\\pytorch_p3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MSY\\anaconda3\\envs\\pytorch_p3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a1f379-2a37-4af3-b23d-5a9c61bb49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed258c42-d782-4009-ac3d-e77312be2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e277286b-d821-42d7-a76b-36b3334a2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb45040-d4b8-470c-9916-fcfa3638437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232ef9d6-4de4-422e-b990-730e9f36e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_input_len=1024, max_output_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = df['text'].tolist()\n",
    "        self.targets = df['summary'].tolist()\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_output_len = max_output_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.inputs[idx]\n",
    "        target_text = self.targets[idx]\n",
    "\n",
    "        inputs = self.tokenizer(input_text, max_length=self.max_input_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        targets = self.tokenizer(target_text, max_length=self.max_output_len, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs.input_ids.squeeze(),\n",
    "            'attention_mask': inputs.attention_mask.squeeze(),\n",
    "            'labels': targets.input_ids.squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9adecd76-7cde-4bcb-a0c8-5c46ed1620e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gogamza/kobart-summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-summarization\").to(device)\n",
    "# 데이터셋 생성\n",
    "train_dataset = SummarizationDataset(train_df, tokenizer)\n",
    "val_dataset = SummarizationDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5e8eb9-28e2-4d93-99fb-c00eb05a3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/summary',                # 결과가 저장될 경로\n",
    "    num_train_epochs=3,                    # 학습할 에폭 수\n",
    "    per_device_train_batch_size=4,         # 학습 시 배치 크기\n",
    "    per_device_eval_batch_size=4,          # 평가 시 배치 크기\n",
    "    warmup_steps=500,                      # 학습 초기에 학습률을 천천히 증가시키는 단계 수\n",
    "    weight_decay=0.01,                     # 가중치 감쇠를 위한 값\n",
    "    logging_dir='/summary/logs',                  # 로그가 저장될 경로\n",
    "    logging_steps=10,                      # 로그를 기록할 스텝 수\n",
    "    evaluation_strategy=\"epoch\",           # 평가 전략\n",
    "    save_strategy=\"epoch\",                 # 체크포인트 저장 전략\n",
    "    save_total_limit=2,                     # 저장할 체크포인트의 최대 수\n",
    "    # device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "805a341a-c7a4-49d6-ab0f-536e23ce6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 초기화\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49fc9c3-c6d0-4a41-bfe8-dc109ad663d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='44031' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    6/44031 00:05 < 17:55:51, 0.68 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465adf2-fbe2-4dfa-a7a1-e205fb3ff230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./kobart-summarization-finetuned\")\n",
    "tokenizer.save_pretrained(\"./kobart-summarization-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a74c73-4c15-47a8-992c-8ea586d3da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까. ...\n",
    "\"\"\"\n",
    "\n",
    "# 입력 텍스트를 토크나이즈\n",
    "inputs = tokenizer(input_text, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "# 모델을 사용해 요약 생성\n",
    "summary_ids = model.generate(inputs.input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "\n",
    "# 생성된 요약 디코딩\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcba8fa-f7a7-4f2b-a5e7-edd59dddf11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
